{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code I'm using to:\n",
    "\n",
    "1. Get data from the internet on Premier League final results between 2008 and 2023\n",
    "2. Select all teams in each season covered by this 15-year range\n",
    "3. Draw career data for each player in the squad of all teams\n",
    "4. Check how relevant they were in those squads\n",
    "5. Get their number of total appearances and starts BEFORE the season in which they played for a PL team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PL table data scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.<yourWebsiteHere>.net'\n",
    "schedule_url_pattern = base_url + '/schedule/eng-premier-league-{}-{}-spieltag/38/'\n",
    "\n",
    "for season_start in range(2008, 2023):\n",
    "    season_end = season_start + 1\n",
    "    url = schedule_url_pattern.format(season_start, season_end)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    tables = soup.find_all('table', class_='standard_tabelle')\n",
    "\n",
    "    filename = f'league_table/PL_league_table_{season_start}_{season_end}.csv'\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Position', 'Team', 'Team URL', 'Matches', 'Wins', 'Draws', 'Losses', 'Goals', 'Goal Difference', 'Points'])\n",
    "\n",
    "        for table in tables:\n",
    "            headers = [th.text for th in table.find_all('th')]\n",
    "            if headers[:4] == ['#', 'Team', 'M.', 'W']:\n",
    "                for row in table.find_all('tr')[1:]:\n",
    "                    columns = row.find_all('td')\n",
    "                    position = columns[0].text.strip()\n",
    "                    team = columns[2].text.strip()\n",
    "                    team_url = base_url + columns[2].a['href'] if columns[2].a else ''\n",
    "                    matches = columns[3].text.strip()\n",
    "                    wins = columns[4].text.strip()\n",
    "                    draws = columns[5].text.strip()\n",
    "                    losses = columns[6].text.strip()\n",
    "                    goals = columns[7].text.strip()\n",
    "                    goal_difference = columns[8].text.strip()\n",
    "                    points = columns[9].text.strip()\n",
    "\n",
    "                    writer.writerow([position, team, team_url, matches, wins, draws, losses, goals, goal_difference, points])\n",
    "\n",
    "    print(f\"Data extraction completed for the {season_start}-{season_end} season.\")\n",
    "    time.sleep(random.randint(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting PL teams in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams_per_season = {}\n",
    "\n",
    "for season_start in range(2008, 2023):\n",
    "    season_end = season_start + 1\n",
    "    filename = f'league_table/PL_league_table_{season_start}_{season_end}.csv'\n",
    "    \n",
    "    with open(filename, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        all_teams = []\n",
    "        for row in reader:\n",
    "            team_position = row[0]\n",
    "            team_name = row[1]\n",
    "            team_url = row[2]\n",
    "            all_teams.append((team_position, team_name, team_url))\n",
    "        all_teams_per_season[f\"{season_start}-{season_end}\"] = all_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams_per_season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing squads for each PL season between 2008 and 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_player_data(url, league_position):\n",
    "    response = requests.get(url)\n",
    "    response.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    base_url = 'https://www.<yourWebsiteHere>.net'  # Base URL for concatenation\n",
    "    players_data = {'Goalkeeper': [], 'Defender': [], 'Midfielder': [], 'Forward': []}\n",
    "    current_position = None\n",
    "\n",
    "    for row in soup.find_all('tr'):\n",
    "        if row.th and row.th.get_text(strip=True) in players_data:\n",
    "            current_position = row.th.get_text(strip=True)\n",
    "        elif row.find_all('td') and current_position:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) >= 6:  \n",
    "                player_summary_link = base_url + cols[2].a['href'] if cols[2].a else None\n",
    "                player_info = {\n",
    "                    'league_position': league_position,\n",
    "                    'name': cols[2].get_text(strip=True),\n",
    "                    'position': current_position,\n",
    "                    'number': cols[1].get_text(strip=True),\n",
    "                    'country': cols[4].get_text(strip=True),\n",
    "                    'dob': cols[5].get_text(strip=True),\n",
    "                    'profile_url': player_summary_link\n",
    "                }\n",
    "                players_data[current_position].append(player_info)\n",
    "\n",
    "    return players_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('team_squads', exist_ok=True)\n",
    "\n",
    "for season, teams in all_teams_per_season.items():\n",
    "    season_end_year = season.split('-')[1]\n",
    "\n",
    "    for team_position, team_name, team_base_url in teams:\n",
    "        team_url = f'{team_base_url}{season_end_year}/2/'\n",
    "\n",
    "        players_data = fetch_player_data(team_url, team_position)\n",
    "\n",
    "        team_dir = f'team_squads/{team_name.replace(\" \", \"_\")}'\n",
    "        os.makedirs(team_dir, exist_ok=True)\n",
    "\n",
    "        filename = f'{team_dir}/{team_name.replace(\" \", \"_\")}_{season}.csv'\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['League Position', 'Position', 'Name', 'Number', 'Country', 'DOB', 'Profile URL'])\n",
    "\n",
    "            for position, players in players_data.items():\n",
    "                for player in players:\n",
    "                    writer.writerow([player['league_position'], player['position'], player['name'],\n",
    "                                     player['number'], player['country'], player['dob'], player['profile_url']])\n",
    "\n",
    "        print(f\"Data extraction completed for {team_name} in the {season} season.\")\n",
    "        time.sleep(random.randint(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing career data for each player in a PL team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_player_career_data(player_url):\n",
    "    career_data = []\n",
    "    response = requests.get(player_url + '2/')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    table = soup.find('table', class_='standard_tabelle')\n",
    "    if table:\n",
    "        rows = table.find_all('tr')[1:]\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                data = {\n",
    "                    'League': cols[1].get_text(strip=True),\n",
    "                    'Season': cols[2].get_text(strip=True),\n",
    "                    'Team': cols[3].get_text(strip=True),\n",
    "                    'Matches': cols[4].get_text(strip=True),\n",
    "                    'Goals': cols[5].get_text(strip=True),\n",
    "                    'Starting Line-Up': cols[6].get_text(strip=True),\n",
    "                    'Substitute In': cols[7].get_text(strip=True),\n",
    "                    'Substitute Out': cols[8].get_text(strip=True),\n",
    "                    'Yellow Cards': cols[9].get_text(strip=True),\n",
    "                    'Second Yellow Cards': cols[10].get_text(strip=True),\n",
    "                    'Red Cards': cols[11].get_text(strip=True)\n",
    "                }\n",
    "                career_data.append(data)\n",
    "    return career_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_urls_from_csv(root_directory):\n",
    "    all_player_urls = []\n",
    "    for subdir, dirs, files in os.walk(root_directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.csv'):\n",
    "                filepath = os.path.join(subdir, filename)\n",
    "                with open(filepath, mode='r', encoding='utf-8') as file:\n",
    "                    reader = csv.DictReader(file)\n",
    "                    for row in reader:\n",
    "                        profile_url = row.get('Profile URL')\n",
    "                        if profile_url:\n",
    "                            all_player_urls.append(profile_url)\n",
    "    return all_player_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_squads_dir = 'team_squads'\n",
    "player_urls = get_player_urls_from_csv(team_squads_dir)\n",
    "player_urls = list(set(player_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'top_players'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "for player_url in player_urls:\n",
    "    career_data = fetch_player_career_data(player_url)\n",
    "    \n",
    "    time.sleep(random.randint(5, 10))\n",
    "\n",
    "    if career_data:\n",
    "        player_name = player_url.rstrip('/').split('/')[-1]\n",
    "\n",
    "        player_directory = os.path.join(output_directory, player_name)\n",
    "        os.makedirs(player_directory, exist_ok=True)\n",
    "\n",
    "        csv_file_path = os.path.join(player_directory, f'{player_name}_career_data.csv')\n",
    "\n",
    "        with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=career_data[0].keys())\n",
    "            writer.writeheader()\n",
    "            for data in career_data:\n",
    "                writer.writerow(data)\n",
    "        print(f\"Career data for {player_name} saved to {csv_file_path}\")\n",
    "    else:\n",
    "        print(f\"No career data found for {player_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check player's career history and PL season role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_before_season(player_season, current_season):\n",
    "    try:\n",
    "        if '/' in player_season:\n",
    "            season_end_year = int(player_season.split('/')[1])\n",
    "        else:\n",
    "            season_end_year = int(player_season)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "    current_season_end_year = int(current_season.split('-')[1])\n",
    "\n",
    "    return season_end_year < current_season_end_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_player_career_data_from_csv(csv_file_path):\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        return list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_role(starts):\n",
    "    if starts >= 19:\n",
    "        return \"1st choice\"\n",
    "    elif 8 <= starts < 19:\n",
    "        return \"2nd choice\"\n",
    "    else:\n",
    "        return \"3rd choice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url_to_name_mapping(team_squads_dir):\n",
    "    url_to_name = {}\n",
    "    for subdir, dirs, files in os.walk(team_squads_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "                with open(filepath, mode='r', encoding='utf-8') as f:\n",
    "                    reader = csv.DictReader(f)\n",
    "                    for row in reader:\n",
    "                        url_to_name[row['Profile URL']] = row['Name']\n",
    "    return url_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_squads_dir = 'team_squads'\n",
    "url_to_name_mapping = create_url_to_name_mapping(team_squads_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url_to_position_mapping(team_squads_dir):\n",
    "    url_to_position = {}\n",
    "    for subdir, dirs, files in os.walk(team_squads_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "                with open(filepath, mode='r', encoding='utf-8') as f:\n",
    "                    reader = csv.DictReader(f)\n",
    "                    for row in reader:\n",
    "                        url_to_position[row['Profile URL']] = row['Position']\n",
    "    return url_to_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_squads_dir = 'team_squads'\n",
    "url_to_position_mapping = create_url_to_position_mapping(team_squads_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_position_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age(dob, end_date):\n",
    "    if dob != 'Unknown':\n",
    "        dob_date = datetime.strptime(dob, \"%d/%m/%Y\").date()\n",
    "        end_date = end_date.date()\n",
    "        age = (end_date - dob_date).days // 365\n",
    "        return age\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url_to_dob_mapping(team_squads_dir):\n",
    "    url_to_dob = {}\n",
    "    for subdir, dirs, files in os.walk(team_squads_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "                with open(filepath, mode='r', encoding='utf-8') as f:\n",
    "                    reader = csv.DictReader(f)\n",
    "                    for row in reader:\n",
    "                        url_to_dob[row['Profile URL']] = row['DOB']\n",
    "    return url_to_dob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_squads_dir = 'team_squads'\n",
    "url_to_dob_mapping = create_url_to_dob_mapping(team_squads_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_dob_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_int(value, default=0):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_starts_appearances(player_data, season, top_competitions):\n",
    "    top_starts_before_season = 0\n",
    "    top_appearances_before_season = 0\n",
    "    total_starts_before_season = 0\n",
    "    total_before_season = 0\n",
    "    for d in player_data:\n",
    "        if is_before_season(d['Season'], season):\n",
    "            if d['League'] in top_competitions:\n",
    "                top_starts_before_season += safe_int(d['Starting Line-Up'])\n",
    "                top_appearances_before_season += safe_int(d['Matches'])\n",
    "            total_starts_before_season += safe_int(d['Starting Line-Up'])\n",
    "            total_before_season += safe_int(d['Matches'])\n",
    "    return top_starts_before_season, top_appearances_before_season, total_starts_before_season, total_before_season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_summaries_dir = 'season_summaries'\n",
    "team_summaries_dir = 'team_summaries'\n",
    "os.makedirs(season_summaries_dir, exist_ok=True)\n",
    "os.makedirs(team_summaries_dir, exist_ok=True)\n",
    "\n",
    "top_competitions = [\n",
    "    \"Primera\", \"EL\", \"Conf. League\", \"Ch. League\", \"UEFA Sup. Cup\",\n",
    "    \"Pr. League\", \"CL QF\", \"EL QF\", \"FA Cup\", \"League Cup\", \"Copa del Rey\",\n",
    "    \"UECL Qual.\", \"Ligue 1\", \"Bundesliga\", \"DFB-Pokal\", \"Coupe\", \"Coupe Ligue\",\n",
    "    \"Serie A\", \"Coppa\", \"Copa Lib.\", \"Copa Sud.\"\n",
    "]\n",
    "\n",
    "player_directory = 'top_players'\n",
    "fieldnames = [\n",
    "    'League Position', 'Player Name', 'Player Position', 'Player URL', 'Team', 'Season', 'Role', \n",
    "    'Age at End of Season', 'PL Starts This Season', 'PL Appearances This Season',\n",
    "    'Top Competition Starts Before Season', 'Top Competition Appearances Before Season',\n",
    "    'Total Starts Before Season', 'Total Appearances Before Season'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season, teams_tuples in all_teams_per_season.items():\n",
    "    season_data = []\n",
    "    team_positions = {team_name: position for position, team_name, _ in teams_tuples}\n",
    "\n",
    "    for _, team_name, _ in teams_tuples:\n",
    "        league_position = team_positions.get(team_name, 'Unknown')\n",
    "        team_dir = os.path.join(team_summaries_dir, team_name.replace(\" \", \"_\"))\n",
    "        os.makedirs(team_dir, exist_ok=True)\n",
    "        team_season_data = []\n",
    "\n",
    "        for player_folder in os.listdir(player_directory):\n",
    "            player_path = os.path.join(player_directory, player_folder, f'{player_folder}_career_data.csv')\n",
    "            if os.path.exists(player_path):\n",
    "                player_data = read_player_career_data_from_csv(player_path)\n",
    "                \n",
    "                for data in player_data:\n",
    "                    data_season_formatted = data['Season'].replace('/', '-')\n",
    "                    if data_season_formatted == season and data['League'] == 'Pr. League' and data['Team'] == team_name:\n",
    "                        starts_this_season = safe_int(data['Starting Line-Up'])\n",
    "                        appearances_this_season = safe_int(data['Matches'])\n",
    "                        starts = safe_int(data['Starting Line-Up'])\n",
    "                        role = determine_role(starts)\n",
    "                        \n",
    "                        top_starts_before_season, top_appearances_before_season, total_starts_before_season, total_before_season = sum_starts_appearances(player_data, season, top_competitions)\n",
    "\n",
    "                        season_end_year = int(season.split('-')[1])\n",
    "                        season_end_date = datetime(season_end_year, 6, 30)\n",
    "                        player_url = f'https://www.<yourWebsiteHere>.net/player_summary/{player_folder}/'\n",
    "                        player_dob = url_to_dob_mapping.get(player_url, 'Unknown')\n",
    "                        if player_dob != 'Unknown':\n",
    "                            player_age = calculate_age(player_dob, season_end_date)\n",
    "                            print(f\"Calculated age for {player_folder}: {player_age}\")\n",
    "                        else:\n",
    "                            player_age = 'Unknown'\n",
    "                        \n",
    "                        player_name = url_to_name_mapping.get(player_url, 'Unknown')\n",
    "                        player_position = url_to_position_mapping.get(player_url, 'Unknown')\n",
    "                        player_summary = {\n",
    "                            'League Position': league_position,\n",
    "                            'Player Name': player_name,\n",
    "                            'Player Position': player_position,\n",
    "                            'Player URL': player_folder,\n",
    "                            'Team': data['Team'],\n",
    "                            'Season': season,\n",
    "                            'Role': role,\n",
    "                            'Age at End of Season': player_age,\n",
    "                            'PL Starts This Season': starts_this_season,\n",
    "                            'PL Appearances This Season': appearances_this_season,\n",
    "                            'Top Competition Starts Before Season': top_starts_before_season,\n",
    "                            'Top Competition Appearances Before Season': top_appearances_before_season,\n",
    "                            'Total Starts Before Season': total_starts_before_season,\n",
    "                            'Total Appearances Before Season': total_before_season\n",
    "                        }\n",
    "                        team_season_data.append(player_summary)\n",
    "                        break\n",
    "\n",
    "        team_csv_path = os.path.join(team_dir, f'{season.replace(\"/\", \"-\")}_{team_name.replace(\" \", \"_\")}_roles.csv')\n",
    "        with open(team_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(team_season_data)\n",
    "        print(f'Saving CSV for {team_name} players in {season} season')\n",
    "        \n",
    "        season_data.extend(team_season_data)\n",
    "\n",
    "    season_csv_path = os.path.join(season_summaries_dir, f'{season}_top_players.csv')\n",
    "    with open(season_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(season_data)\n",
    "    print(f'Saving summary for the {season} season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plus: extracting data from Chelsea's current season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.<yourWebsiteHere>.net'\n",
    "schedule_url_pattern = base_url + '/schedule/eng-premier-league-{}-{}-spieltag/38/'\n",
    "\n",
    "for season_start in range(2023, 2024):\n",
    "    season_end = season_start + 1\n",
    "    url = schedule_url_pattern.format(season_start, season_end)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    tables = soup.find_all('table', class_='standard_tabelle')\n",
    "\n",
    "    filename = f'league_table/PL_league_table_{season_start}_{season_end}.csv'\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Position', 'Team', 'Team URL', 'Matches', 'Wins', 'Draws', 'Losses', 'Goals', 'Goal Difference', 'Points'])\n",
    "\n",
    "        for table in tables:\n",
    "            headers = [th.text for th in table.find_all('th')]\n",
    "            if headers[:4] == ['#', 'Team', 'M.', 'W']:\n",
    "                for row in table.find_all('tr')[1:]:\n",
    "                    columns = row.find_all('td')\n",
    "                    position = columns[0].text.strip()\n",
    "                    team = columns[2].text.strip()\n",
    "                    team_url = base_url + columns[2].a['href'] if columns[2].a else ''\n",
    "                    matches = columns[3].text.strip()\n",
    "                    wins = columns[4].text.strip()\n",
    "                    draws = columns[5].text.strip()\n",
    "                    losses = columns[6].text.strip()\n",
    "                    goals = columns[7].text.strip()\n",
    "                    goal_difference = columns[8].text.strip()\n",
    "                    points = columns[9].text.strip()\n",
    "\n",
    "                    writer.writerow([position, team, team_url, matches, wins, draws, losses, goals, goal_difference, points])\n",
    "\n",
    "    print(f\"Data extraction completed for the {season_start}-{season_end} season.\")\n",
    "    time.sleep(random.randint(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams_2023_2024 = {}\n",
    "\n",
    "for season_start in range(2023, 2024):\n",
    "    season_end = season_start + 1\n",
    "    filename = f'league_table/PL_league_table_{season_start}_{season_end}.csv'\n",
    "    \n",
    "    with open(filename, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        all_teams = []\n",
    "        for row in reader:\n",
    "            team_position = row[0]\n",
    "            team_name = row[1]\n",
    "            team_url = row[2]\n",
    "            all_teams.append((team_position, team_name, team_url))\n",
    "        all_teams_2023_2024[f\"{season_start}-{season_end}\"] = all_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams_2023_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('team_squads', exist_ok=True)\n",
    "\n",
    "for season, teams in all_teams_2023_2024.items():\n",
    "    season_end_year = season.split('-')[1]\n",
    "\n",
    "    for team_position, team_name, team_base_url in teams:\n",
    "        clean_team_name = team_name.replace(\"\\n\", \" \").replace(\"(M,P)\", \"\").replace(\"(N)\", \"\").strip()\n",
    "        team_url = f'{team_base_url}{season_end_year}/2/'\n",
    "\n",
    "        players_data = fetch_player_data(team_url, team_position)\n",
    "\n",
    "        team_dir = f'team_squads/{clean_team_name.replace(\" \", \"_\")}'\n",
    "        os.makedirs(team_dir, exist_ok=True)\n",
    "\n",
    "        filename = f'{team_dir}/{clean_team_name.replace(\" \", \"_\")}_{season}.csv'\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['League Position', 'Position', 'Name', 'Number', 'Country', 'DOB', 'Profile URL'])\n",
    "\n",
    "            for position, players in players_data.items():\n",
    "                for player in players:\n",
    "                    writer.writerow([player['league_position'], player['position'], player['name'],\n",
    "                                     player['number'], player['country'], player['dob'], player['profile_url']])\n",
    "\n",
    "        print(f\"Data extraction completed for {clean_team_name} in the {season} season.\")\n",
    "        time.sleep(random.randint(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_urls_from_2023_2024_csvs(root_directory):\n",
    "    player_urls = []\n",
    "    for subdir, dirs, files in os.walk(root_directory):\n",
    "        for filename in files:\n",
    "            if '2023-2024' in filename and filename.endswith('.csv'):\n",
    "                filepath = os.path.join(subdir, filename)\n",
    "                with open(filepath, mode='r', encoding='utf-8') as file:\n",
    "                    reader = csv.DictReader(file)\n",
    "                    for row in reader:\n",
    "                        profile_url = row.get('Profile URL')\n",
    "                        if profile_url:\n",
    "                            player_urls.append(profile_url)\n",
    "    return player_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_squads_dir = 'team_squads'\n",
    "player_urls = get_player_urls_from_2023_2024_csvs(team_squads_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_player_career_data_2023_2024(player_url):\n",
    "    career_data = []\n",
    "    response = requests.get(player_url + '2/')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    table = soup.find('table', class_='standard_tabelle')\n",
    "    if table:\n",
    "        rows = table.find_all('tr')[1:]\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                data = {\n",
    "                    'League': cols[1].get_text(strip=True),\n",
    "                    'Season': cols[2].get_text(strip=True),\n",
    "                    'Team': cols[3].get_text(strip=True),\n",
    "                    'Matches': cols[4].get_text(strip=True),\n",
    "                    'Goals': cols[5].get_text(strip=True),\n",
    "                    'Starting Line-Up': cols[6].get_text(strip=True),\n",
    "                    'Substitute In': cols[7].get_text(strip=True),\n",
    "                    'Substitute Out': cols[8].get_text(strip=True),\n",
    "                    'Yellow Cards': cols[9].get_text(strip=True),\n",
    "                    'Second Yellow Cards': cols[10].get_text(strip=True),\n",
    "                    'Red Cards': cols[11].get_text(strip=True)\n",
    "                }\n",
    "                career_data.append(data)\n",
    "    return [data for data in career_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'top_players'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "for player_url in player_urls:\n",
    "    career_data = fetch_player_career_data_2023_2024(player_url)\n",
    "    \n",
    "    time.sleep(random.randint(5, 10))\n",
    "\n",
    "    if career_data:\n",
    "        player_name = player_url.rstrip('/').split('/')[-1]\n",
    "\n",
    "        player_directory = os.path.join(output_directory, player_name)\n",
    "        os.makedirs(player_directory, exist_ok=True)\n",
    "\n",
    "        csv_file_path = os.path.join(player_directory, f'{player_name}_career_data.csv')\n",
    "\n",
    "        with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=career_data[0].keys())\n",
    "            writer.writeheader()\n",
    "            for data in career_data:\n",
    "                writer.writerow(data)\n",
    "        print(f\"Career data for {player_name} for 2023-2024 season saved to {csv_file_path}\")\n",
    "    else:\n",
    "        print(f\"No career data found for {player_url} for the 2023-2024 season\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023-24 final data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_summaries_dir = 'season_summaries'\n",
    "team_summaries_dir = 'team_summaries'\n",
    "os.makedirs(season_summaries_dir, exist_ok=True)\n",
    "os.makedirs(team_summaries_dir, exist_ok=True)\n",
    "\n",
    "top_competitions = [\n",
    "    \"Primera\", \"EL\", \"Conf. League\", \"Ch. League\", \"UEFA Sup. Cup\",\n",
    "    \"Pr. League\", \"CL QF\", \"EL QF\", \"FA Cup\", \"League Cup\", \"Copa del Rey\",\n",
    "    \"UECL Qual.\", \"Ligue 1\", \"Bundesliga\", \"DFB-Pokal\", \"Coupe\", \"Coupe Ligue\",\n",
    "    \"Serie A\", \"Coppa\", \"Copa Lib.\", \"Copa Sud.\"\n",
    "]\n",
    "\n",
    "player_directory = 'top_players'\n",
    "fieldnames = [\n",
    "    'League Position', 'Player Name', 'Player Position', 'Player URL', 'Team', 'Season', 'Role', \n",
    "    'Age at End of Season', 'PL Starts This Season', 'PL Appearances This Season',\n",
    "    'Top Competition Starts Before Season', 'Top Competition Appearances Before Season',\n",
    "    'Total Starts Before Season', 'Total Appearances Before Season'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams_per_season = {}\n",
    "\n",
    "for season_start in range(2023, 2024):\n",
    "    season_end = season_start + 1\n",
    "    filename = f'league_table/PL_league_table_{season_start}_{season_end}.csv'\n",
    "    \n",
    "    with open(filename, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        all_teams = []\n",
    "        for row in reader:\n",
    "            team_position = row[0]\n",
    "            team_name = row[1]\n",
    "            team_url = row[2]\n",
    "            all_teams.append((team_position, team_name, team_url))\n",
    "        all_teams_per_season[f\"{season_start}-{season_end}\"] = all_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams_per_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_summaries_dir = 'season_summaries'\n",
    "team_summaries_dir = 'team_summaries'\n",
    "os.makedirs(season_summaries_dir, exist_ok=True)\n",
    "os.makedirs(team_summaries_dir, exist_ok=True)\n",
    "\n",
    "target_season = '2023-2024'\n",
    "\n",
    "clean_team_name = team_name.replace(\"\\n\", \" \").replace(\"(M,P)\", \"\").replace(\"(N)\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season, teams_tuples in all_teams_per_season.items():\n",
    "    season_data = []\n",
    "    team_positions = {team_name: position for position, team_name, _ in teams_tuples}\n",
    "\n",
    "    for _, team_name, _ in teams_tuples:\n",
    "        clean_team_name = team_name.replace(\"\\n\", \" \").replace(\"(M,P)\", \"\").replace(\"(N)\", \"\").strip()\n",
    "        league_position = team_positions.get(team_name, 'Unknown')\n",
    "        team_dir = os.path.join(team_summaries_dir, clean_team_name.replace(\" \", \"_\"))\n",
    "        os.makedirs(team_dir, exist_ok=True)\n",
    "        team_season_data = []\n",
    "\n",
    "        for player_folder in os.listdir(player_directory):\n",
    "            player_path = os.path.join(player_directory, player_folder, f'{player_folder}_career_data.csv')\n",
    "            if os.path.exists(player_path):\n",
    "                player_data = read_player_career_data_from_csv(player_path)\n",
    "                \n",
    "                for data in player_data:\n",
    "                    data_season_formatted = data['Season'].replace('/', '-')\n",
    "                    if data_season_formatted == target_season and data['League'] == 'Pr. League' and data['Team'] == team_name:\n",
    "                        starts_this_season = safe_int(data['Starting Line-Up'])\n",
    "                        appearances_this_season = safe_int(data['Matches'])\n",
    "                        starts = safe_int(data['Starting Line-Up'])\n",
    "                        role = determine_role(starts)\n",
    "                        \n",
    "                        top_starts_before_season, top_appearances_before_season, total_starts_before_season, total_before_season = sum_starts_appearances(player_data, season, top_competitions)\n",
    "\n",
    "                        season_end_year = int(season.split('-')[1])\n",
    "                        season_end_date = datetime(season_end_year, 6, 30)\n",
    "                        player_url = f'https://www.<yourWebsiteHere>.net/player_summary/{player_folder}/'\n",
    "                        player_dob = url_to_dob_mapping.get(player_url, 'Unknown')\n",
    "                        if player_dob != 'Unknown':\n",
    "                            player_age = calculate_age(player_dob, season_end_date)\n",
    "                            print(f\"Calculated age for {player_folder}: {player_age}\")\n",
    "                        else:\n",
    "                            player_age = 'Unknown'\n",
    "                        \n",
    "                        player_name = url_to_name_mapping.get(player_url, 'Unknown')\n",
    "                        player_position = url_to_position_mapping.get(player_url, 'Unknown')\n",
    "                        player_summary = {\n",
    "                            'League Position': league_position,\n",
    "                            'Player Name': player_name,\n",
    "                            'Player Position': player_position,\n",
    "                            'Player URL': player_folder,\n",
    "                            'Team': data['Team'],\n",
    "                            'Season': season,\n",
    "                            'Role': role,\n",
    "                            'Age at End of Season': player_age,\n",
    "                            'PL Starts This Season': starts_this_season,\n",
    "                            'PL Appearances This Season': appearances_this_season,\n",
    "                            'Top Competition Starts Before Season': top_starts_before_season,\n",
    "                            'Top Competition Appearances Before Season': top_appearances_before_season,\n",
    "                            'Total Starts Before Season': total_starts_before_season,\n",
    "                            'Total Appearances Before Season': total_before_season\n",
    "                        }\n",
    "                        team_season_data.append(player_summary)\n",
    "                        break\n",
    "\n",
    "        team_csv_path = os.path.join(team_dir, f'{season.replace(\"/\", \"-\")}_{clean_team_name.replace(\" \", \"_\")}_roles.csv')\n",
    "        with open(team_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(team_season_data)\n",
    "        print(f'Saving CSV for {clean_team_name} players in {season} season')\n",
    "        \n",
    "        season_data.extend(team_season_data)\n",
    "\n",
    "    season_csv_path = os.path.join(season_summaries_dir, f'{season}_top_players.csv')\n",
    "    with open(season_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(season_data)\n",
    "    print(f'Saving summary for the {season} season')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
